---
title: "map501_F416781"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
date: "2024-11-25"
---


## Setting up

```{r}
knitr::opts_chunk$set(
 results = "hold", echo = TRUE, eval = TRUE,
 message = FALSE, fig.width = 7, warning = FALSE,
 fig.height = 4, fig.align = "center"
)

```

## Installing needed 
```{r, echo=FALSE}
# List of required packages
packages <- c("tidyverse", "magrittr", "here", "janitor", "gridExtra", 
              "readxl", "Lahman", "viridis", "lindia", "lme4", "caret", 
              "pROC", "car")

# Install missing packages
for (pkg in packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
  }
  library(pkg, character.only = TRUE)
}

# Confirm the loaded libraries
print("All specified libraries have been installed and loaded.")
 

```

### Loading libraries to be used


```{r}
library("tidyverse")
 library("magrittr")
 library("here")
 library("janitor")
 library("gridExtra")
 library("readxl")
 library("Lahman")
 library("viridis")
 library("lindia")
 library("lme4")
 library("caret")
 library("pROC")
 library("car")
```
## 1. Linear Regression
### a. Creating df_managers with win_pct and selected variables
```{r}

# Create the df_managers dataset (W= Win, G= Game)
df_managers <- Managers %>%
  mutate(win_pct = W / G) %>%
  select(playerID, teamID, yearID, lgID, plyrMgr, win_pct)

# Check the structure of df_managers
str(df_managers)

```
### b. Create awards_man dataset
#### i. Create df_teams
```{r}
df_teams <- Teams %>%
  select(yearID, teamID, DivWin, CS)

# Check the structure of df_teams
str(df_teams)

```

#### ii. Create man_teams by merging df_managers with df_teams and remove lgID

```{r}
man_teams <- merge(df_managers, df_teams, by = c("yearID", "teamID")) %>%
  select(-lgID)

# Check the structure of man_teams
str(man_teams)
```

#### iii. Merge man_teams with AwardsShareManagers to create awards_man
```{r}
awards_man <- merge(man_teams, AwardsShareManagers, by = c("yearID", "playerID"))

# Check the structure of awards_man
str(awards_man)
```

#### iv. Add sqr_point_pct to awards_man
```{r}
awards_man <- awards_man %>%
  mutate(sqr_point_pct = sqrt(pointsWon / pointsMax))
```

#### v. Remove incomplete cases and drop unused levels of teamID
```{r}
awards_man <- awards_man %>%
  na.omit() %>%
  droplevels()

# Check the cleaned awards_man dataset
str(awards_man)
```

### c. Fit Gaussian model spp_mod
```{r}
# Fit the model
spp_mod <- lm(sqr_point_pct ~ win_pct + DivWin + CS, data = awards_man)

# Summarize the results
summary(spp_mod)
```
The linear regression model predicts sqr_point_pct using win_pct, DivWin, and CS as predictors. The fitted model is:  

        sqr_point_pct = -0.73 + 1.81*win_pct + 0.14*DivWinY + 0.003*CS

Intercept: The intercept (-0.73) indicates the baseline value of sqr_point_pct when all predictors are zero. While not directly meaningful in this context, it provides a reference point for the model.

win_pct: For every unit increase in win_pct, the sqr_point_pct is expected to increase by 1.81, holding other variables constant. This effect is highly significant (p-value = 2.67e-12), showing a strong positive relationship.

DivWin: Teams that win their division (DivWinY = 1) have an average sqr_point_pct that is 0.14 higher than those that do not (DivWinY = 0), controlling for other factors. This relationship is also highly significant (p-value = 4.42e-07).

CS: Each additional unit of CS corresponds to an increase of 0.003 in sqr_point_pct, with a highly significant p-value of 1.62e-05. Although the effect is small, it is statistically important.

Model fit: 
The model explains 27.1% of the variance in sqr_point_pct (Multiple R-squared = 0.271). The residual standard error is 0.2401, suggesting the model fits the data reasonably well.


### d. Evaluate model assumptions
```{r}
# Plot residuals to check assumptions
par(mfrow = c(2, 2))
plot(spp_mod)

# Check for multicollinearity
library(car)
vif(spp_mod)
```

### e. Predict sqr_point_pct when win_pct = 0.8, DivWin = Yes, and CS = 8
```{r}
# Create new data for prediction
new_data <- data.frame(
  win_pct = 0.8, 
  DivWin = factor("Yes", levels = levels(awards_man$DivWin)), 
  CS = 8
)

# Predict the expected value
predicted_value <- predict(spp_mod, new_data)
predicted_value
```

### f. Construct 95% confidence intervals for parameter estimates
```{r}
# Confidence intervals
conf_intervals <- confint(spp_mod, level = 0.95)
conf_intervals
```
## 2. Logistic Regression
### a. Plot plyrMgr Against yearID
```{r}

# Jitter the points vertically to visualize plyrMgr vs. yearID
ggplot(df_managers, aes(x = yearID, y = as.numeric(plyrMgr))) +
  geom_jitter(height = 0.2, width = 0, color = "blue", alpha = 0.6) +
  scale_y_continuous(breaks = c(0, 1), labels = c("Not Player-Manager", "Player-Manager")) +
  labs(title = "Player-Manager Status Over Time", x = "Year", y = "Player-Manager Status") +
  theme_minimal()
```
Comment:
The graph may show a decline in player-managers over time as specialization in the manager role increased.

### b.Fitting Logistic Regression Model
```{r}
# Logistic regression for plyrMgr as a function of yearID
logit_model <- glm(plyrMgr ~ yearID, data = df_managers, family = "binomial")

# Summarize the model
summary(logit_model)

# Report and interpret results
# Formula: log(odds) = β0 + β1 * yearID
# Extract and round coefficients
rounded_coefs <- round(coef(logit_model), 2)

# Print the rounded coefficients
rounded_coefs
```
The logistic regression model predicts the probability of being a player-manager (plyrMgr) based on the year (yearID). The fitted equation is:  
            {logit}(p) = 88.60 - 0.05*{yearID}
 
where p is the probability of a manager being a player.

The yearID coefficient (-0.05, p < 2e-16) indicates that each passing year decreases the log-odds of being a player-manager by 0.05. This corresponds to a 5% reduction in odds per year (e^{-0.05} approximately equal to 0.95), showing a significant decline in the prevalence of player-managers over time.

The model significantly reduces variability, as seen in the drop from a null deviance of 3442.4 to a residual deviance of 2127.7, with an AIC of 2131.7, suggesting a good fit. This supports the conclusion that being a player-manager has become increasingly rare over time.

### c. Checking for Overfitting Using 80%-20% Split
```{r}
set.seed(123)
train_indices <- sample(seq_len(nrow(df_managers)), size = 0.8 * nrow(df_managers))
train_data <- df_managers[train_indices, ]
test_data <- df_managers[-train_indices, ]
```

#### Fit Model on Training Data
```{r}
train_model <- glm(plyrMgr ~ yearID, data = train_data, family = "binomial")
```

#### ROC Curves
```{r}
library(pROC)

# Predict probabilities for training and testing data
train_probs <- predict(train_model, newdata = train_data, type = "response")
test_probs <- predict(train_model, newdata = test_data, type = "response")

# Generate ROC curves
roc_train <- roc(train_data$plyrMgr, train_probs)
roc_test <- roc(test_data$plyrMgr, test_probs)

# Plot ROC curves
plot(roc_train, col = "blue", main = "ROC Curve: Train vs. Test")
plot(roc_test, col = "red", add = TRUE)
legend("bottomright", legend = c("Train", "Test"), col = c("blue", "red"), lty = 1)
```
The test curve lies above the train curve at a given point, this suggests superior performance.
It is also evident that there is intersections between the curves, this indicate scenarios where one model might outperform the other depending on the specific threshold.

### d. Youden’s Index and Confusion Matrices
```{r}
# Make predictions on the training data
train_preds <- predict(logit_model, newdata = train_data, type = "response")

# Make predictions on the testing data
test_preds <- predict(logit_model, newdata = test_data, type = "response")

```
```{r}
# For training Data
# Convert probabilities into binary outcomes (using 0.5 as the cutoff)
train_preds_class <- ifelse(train_preds > 0.5, 1, 0)

# Confusion matrix for training data
train_confusion_matrix <- table(Predicted = train_preds_class, Actual = train_data$plyrMgr)
print(train_confusion_matrix)

# Calculate Youden’s Index for training data
train_sensitivity <- train_confusion_matrix[2, 2] / (train_confusion_matrix[2, 1] + train_confusion_matrix[2, 2])
train_specificity <- train_confusion_matrix[1, 1] / (train_confusion_matrix[1, 1] + train_confusion_matrix[1, 2])
train_youden_index <- train_sensitivity + train_specificity - 1
print(paste("Training Youden's Index:", train_youden_index))

```
```{r}
# For testing data
# Convert probabilities into binary outcomes (using 0.5 as the cutoff)
test_preds_class <- ifelse(test_preds > 0.5, 1, 0)

# Confusion matrix for testing data
test_confusion_matrix <- table(Predicted = test_preds_class, Actual = test_data$plyrMgr)
print(test_confusion_matrix)

# Calculate Youden’s Index for testing data
test_sensitivity <- test_confusion_matrix[2, 2] / (test_confusion_matrix[2, 1] + test_confusion_matrix[2, 2])
test_specificity <- test_confusion_matrix[1, 1] / (test_confusion_matrix[1, 1] + test_confusion_matrix[1, 2])
test_youden_index <- test_sensitivity + test_specificity - 1
print(paste("Testing Youden's Index:", test_youden_index))
```
Comment:
The model's performance, as indicated by the Youden's Index, shows moderate effectiveness in both training and testing datasets. The Youden’s Index for the training data is 0.4498, while for the testing data, it is 0.4437, suggesting that the model performs similarly on both sets. The confusion matrix for the training data reveals a high specificity (0.927), meaning the model does well at identifying players who are not managed by a manager, but it struggles with a relatively low sensitivity (0.442), missing many true positives. The testing data shows a slight drop in specificity (0.912) and a slight improvement in sensitivity (0.525), indicating that while the model generalizes well to new data, it still underperforms in identifying positive cases. Overall, the model has a moderate ability to classify the negative class, but it misses many positives, suggesting the need for improvement. Adjusting the cutoff threshold, incorporating more features, or experimenting with different classification models could enhance performance, particularly in detecting positives.

### e. Sensitivity+Specificity by lgID
```{r}

# Add predictions to test data
test_data <- test_data %>%
  mutate(Predicted = test_preds)

# Compute sensitivity and specificity for each lgID
metrics_by_lgID <- test_data %>%
  group_by(lgID) %>%
  summarise(
    Sensitivity = sum(Predicted == 1 & plyrMgr == 1) / sum(plyrMgr == 1),
    Specificity = sum(Predicted == 0 & plyrMgr == 0) / sum(plyrMgr == 0),
    Sum = Sensitivity + Specificity
  )

# Plot bar chart
ggplot(metrics_by_lgID, aes(x = lgID, y = Sum, fill = lgID)) +
  geom_bar(stat = "identity") +
  labs(title = "Sum of Sensitivity and Specificity by lgID", x = "lgID", y = "Sensitivity + Specificity") +
  theme_minimal()

# Comment: Interpret variations in model performance across different leagues.
```
### f. Adding win_pct to the Model
```{r}
logit_model_extended <- glm(plyrMgr ~ yearID + win_pct, data = df_managers, family = "binomial")

# Compare the models
summary(logit_model)
summary(logit_model_extended)

# Compare AIC values
AIC(logit_model, logit_model_extended)
```
The logit_model is preferred over the logit_model_extended because it has a slightly lower AIC (2131.660 vs. 2133.658), indicating a better balance between fit and complexity. A lower AIC suggests that logit_model offers a more parsimonious fit without unnecessary complexity, making it the better model to avoid overfitting. Therefore, logit_model is the preferred choice.

## 3. Poisson Regression
### a. Create df_pitchers
```{r}
library(Lahman)
library(dplyr)

# i. Filter Pitching dataset for pitchers who faced at least 1 batter
df_pitchers <- Pitching %>%
  filter(BFP > 0)

# ii. Add "innings" variable
df_pitchers <- df_pitchers %>%
  mutate(innings = IPouts / 3)

# iii. Add variables from the People dataset
df_pitchers <- df_pitchers %>%
  left_join(select(People, playerID, weight, height, throws), by = "playerID")

# iv. Remove incomplete cases
df_pitchers <- na.omit(df_pitchers)

# View dataset
head(df_pitchers)
```
### b. Histogram of shutouts
```{r}
# Plot a histogram of the number of shutouts
hist(df_pitchers$SHO, breaks = 30, col = "skyblue", main = "Histogram of Shutouts", xlab = "Number of Shutouts")
```
Poisson models are suitable for count data like shutouts because:
- Shutouts are non-negative integer values.
- The data represents rare events, which aligns with the Poisson distribution assumptions.

### c. Graph of shutouts vs innings pitched
```{r}
library(ggplot2)

# Plot shutouts as a function of innings pitched, colored by throwing hand
ggplot(df_pitchers, aes(x = innings, y = SHO, color = throws)) +
  geom_jitter(width = 0, height = 0.1, alpha = 0.7) +
  labs(title = "Shutouts vs Innings Pitched",
       x = "Innings Pitched",
       y = "Number of Shutouts",
       color = "Throwing Hand") +
  theme_minimal()
```
Comment:
The graph shows a positive relationship between innings pitched and shutouts.
Left-handed and right-handed pitchers are distributed similarly, with slightly more variation among right-handed pitchers.

### d. Multiple Poisson regression model
```{r}
# Fit a Poisson regression model
poisson_mod1 <- glm(SHO ~ innings + weight + height + throws, 
                    data = df_pitchers, 
                    family = "poisson")

# Model summary
summary(poisson_mod1)

# Analysis of variance for p-values
anova_poisson <- anova(poisson_mod1, test = "Chisq")
anova_poisson
```
Interpretation
The Poisson regression model predicts shutouts (SHO) based on innings, weight, height, and throwing hand. **Innings** is the strongest predictor, with each additional inning increasing expected shutouts by 2.1% (\(p < 2e-16\)). **Weight** has a negative impact, reducing expected shutouts by 0.94% per unit increase (\(p < 2e-16\)), while **height** increases expected shutouts by 6.4% per unit (\(p < 2e-16\)). Compared to left-handed pitchers, being **right-handed** slightly decreases shutouts by 10% (\(p = 0.0006\)), but **switch-handedness** has no significant effect. The model fits well, significantly reducing deviance from 26122 to 10607, with an AIC of 18025, indicating strong explanatory power.

### e. Poisson model with random effect (poisson_mod2)
```{r}
# Rescaling variables
df_pitchers <- df_pitchers %>%
  mutate(across(c(innings, weight, height), scale))

# Remove sparse levels or rare categories, if needed
df_pitchers <- df_pitchers %>%
  filter(throws != "S")

# Fit the model
poisson_mod2 <- glmer(SHO ~ innings + weight + height + throws + (1 | teamID),
                      data = df_pitchers,
                      family = "poisson",
                      control = glmerControl(optimizer = "bobyqa"))

# Check the model summary
summary(poisson_mod2)
```
Interpretation
From the model results, it appears that teamID (the random effect) does not play a very significant role as a predictor. Here is why:

1. Variance of the Random Effect
The variance of the random effect for teamID is 0.04886, and the standard deviation is 0.221.
These values are relatively small, indicating that the variation in SHO (shutouts) due to differences between teams is minimal compared to the overall variability in the data.

2. Random Effects vs Fixed Effects
The fixed effects (such as innings, weight, height, and throws) have much larger z-values and highly significant p-values (all < 0.001). This indicates that these variables explain a substantial portion of the variability in SHO.
The small variance of the teamID random effect suggests that the additional grouping structure provided by teamID is not contributing much explanatory power to the model.

### f. Scale-location plot
```{r}
# Scale-location plot for poisson_mod1
plot(poisson_mod1, which = 3)

# Observation:
# The scale-location plot should show no clear pattern if model assumptions hold.
# Deviations suggest issues like heteroscedasticity.
```
Interpretation

### g. Effects of throwing hand, height, and weight
```{r}
# Ensure 'throws' is a factor with the correct levels
df_pitchers$throws <- factor(df_pitchers$throws, levels = c("R", "L"))

# Refit the Poisson model
poisson_mod1 <- glmer(SHO ~ innings + weight + height + throws + (1 | teamID),
                      data = df_pitchers,
                      family = "poisson",
                      control = glmerControl(optimizer = "bobyqa"))

# Extract coefficients
coef_summary <- summary(poisson_mod1)$coefficients

# Check the row names of coefficients
rownames(coef_summary)

# Calculate the effects
exp_coef_throws <- exp(coef_summary["throwsL", "Estimate"]) # Adjust if necessary
exp_coef_height <- exp(coef_summary["height", "Estimate"])
exp_coef_weight <- exp(coef_summary["weight", "Estimate"])

# Output the effects
list(
  "Effect of Left Handed" = exp_coef_throws,
  "Effect of Height" = exp_coef_height,
  "Effect of Weight" = exp_coef_weight
)
```
The results indicate that left-handed pitchers, on average, pitch 1.13 times more shutouts than right-handed pitchers, all other factors being equal. This suggests that left-handed pitchers may have a slight advantage due to their relative scarcity or the challenges batters face when competing against them. Additionally, taller players tend to pitch more shutouts, as the effect of height shows an increase of 1.14 times for every unit increase in height (likely measured in inches). This advantage could be due to the biomechanical benefits taller pitchers possess, such as generating more power or delivering pitches at more challenging angles. Conversely, heavier players pitch fewer shutouts, with the results showing a decrease of 0.82 times for every unit increase in weight (likely in pounds). This finding implies that lighter players might have better stamina or agility, contributing to their ability to pitch more shutouts. These results highlight how physical characteristics such as handedness, height, and weight can influence pitching performance.
